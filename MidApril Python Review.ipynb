{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we're reviewing for-loops in Pythons. First, however, we're going to import the packages that we need. RE is the RegEx package that will let us use regular expressions to search the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is going to be a start to figuring out whether we could make more brownies or chocolate chip cookies with the items in the pantry. The first thing we're going to do is break each recipe into a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Brownies = ['two sticks of butter', 'two tablespoons of vegetable oil', 'one cup of sugar', 'one cup of brown sugar', 'four large eggs', \n",
    "'one tablespoon of vanilla extract', 'one teaspoon of salt', 'one cup of flour', 'seven ounces of chocolate']\n",
    "\n",
    "Cookies = ['three-fourth cup of sugar', 'three-fourth cup of brown sugar', 'two sticks of butter', 'one teaspoon of vanilla extract',\n",
    " 'one egg', 'two cups of flour', 'one teaspoon of baking soda', 'one teaspoon salt', 'twelve ounces of chocolate']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to see what we have in the pantry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pantry = ['six sticks of butter', 'thirty-two tablespoons of vegetable oil', 'five cups of sugar', \n",
    "'three cups of brown sugar', 'twelve large eggs', 'five tablespoons of vanilla extract', 'sixty teaspoons of salt', \n",
    "'five cups of flour', 'twenty-four ounces of chocolate', 'twelve teaspoons of baking soda']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good. But you may notice that we're going to have a problem. We cannot subtract the string 'two sticks of butter' from 'six sticks of butter' and get 'four sticks of butter remaining.' While strings are great for storing alphanumeric characters, they do no allow arithmatic operations the way integers would do. We need to turn 'six' to 6 and 'two' to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data structure we would need for performing these operations would mix strings and integers. As we may remember, a tuple fits the bill. This tuple would render 'six sticks of butter' as (6, 'sticks', 'butter'). The first thing we need to do is build a new list for Brownies that will contain tuples instead of strings. To do this, we create an empty list called Brownies_as_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Brownies_as_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first challenge is to build some code that will turn written representations of numbers (the string 'two' for instance) into an integer. Below is a limited, but good-enough-to-get-the-the-job done list of tuples that will act as a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Word_to_number = [('one', 1), ('two', 2), ('three', 3), ('four', 4), ('five', 5), ('six', 6), ('seven', 7), \n",
    "('eight', 8), ('nine', 9), ('ten', 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing that we need to do is tokenize the strings in our Brownie list. Right now, the individual words are not separated out, meaning that if we tried to iterate through them, we would end up with individual characters instead. Take 'two sticks of butter' for example. If we did not tokenize this and asked for the second item in the string, we would get the 'w' from two. If we tokenized by words and did the same, we would get 'sticks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer below takes and group of characters that are surrounded by whitespace on each side, including those that have an apostrophe or dash in them. This tokenizer would recognize the strings 'can', 'can't', and 'can-can', but not 'Cornell University'( it would instead return 'Cornell' and 'University.' By compiling this regular expression in advance, we are able to call it later as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = re.compile(\"\\w[\\w\\-\\']*\\w|\\w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the code below line by line. What we are trying to do is get three variables, the integer, the measurement, and the food of each ingredient.\n",
    "\n",
    "The first line is saying that for every ingredient in Brownies (which means every string in the list Brownies separated by a comma), we want it to perform the task that follows.\n",
    "\n",
    "The second line uses our tokenizer on each ingredient in the list. This delimits each string into separate words. What was 'two sticks of butter' in the line above is now a list ['two', 'sticks', 'of', 'butter'].\n",
    "\n",
    "The third line calls the Word_to_number list we made. We are introducing every tuple from that list into our loop as i. This means that the first i is ('one, 1')\n",
    "\n",
    "The fourth line says that if the first part of x (x[0] which would be the string 'two' from ['two', 'sticks', 'of', 'butter']) matches the first part of i (i[0], which is 'one' from ('one', 1) then we want the loop to do something.\n",
    "\n",
    "In the fifth line. We declare the variable digit_value as equal to i[1] (which would be 1 from ('one', 1).\n",
    "\n",
    "As you can see, eventually the 'two' from ['two', 'sticks', 'of', 'butter'] will match the 'two' from '(two', 2). It is at this point we know that the integer we want is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ingredient in Brownies:\n",
    "\tx = tokenizer.findall(ingredient)\n",
    "\tfor i in Word_to_number:\n",
    "\t\tif x[0] == i[0]:\n",
    "\t\t\tdigit_value = i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the integer we need, we'll need to work to find the food and measurement in each ingredient. Let's consider ['two', 'sticks', 'of', 'butter'] once more. We know that the food item normally comes after the word 'of' and the measurement before it. Let's imagine, however, that we instead had the ingredient ['two', 'chilled', 'sticks', 'of', 'salted', 'butter']. Saying that we needed only the item immediately before and after 'of' would return 'sticks' and 'salted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To go through the remaining code:\n",
    "\n",
    "The first thing we need to do is turn x ('two', 'sticks', 'of', 'butter') into the number values [0, 1, 2 ,3] so that if 'of' is equal to 2, we know that we need 1 and 3. As such, we define t as the length of all of the tokens in x (4) and ask for the range of that length [0, 1, 2, 3].\n",
    "\n",
    "The next line says that once x at one of those numbers is equal to 'of', we want it to do something. So, if of happens in the third token of ['two', 'sticks', 'of', 'butter'], the t in x[t] is equal to 2, whereas in ['two', 'chilled', 'sticks', 'of', 'salted', 'butter'] the t in x[t] is equal to 3.\n",
    "\n",
    "The next two lines will define variables based on the position of the word of. For food, we are asking python to join every item that comes after the word 'of' as one string. This means that if the list was ['two', 'chilled', 'sticks', 'of', 'salted', 'butter', 'from', 'organic', 'humanely-raised','Maine', 'cows'] the food variable would read 'salted butter from organic humanely-raised Maine cows.' The measurement variable is equal to the token that comes before 'of', though we could change this in case we had a multi-word measurement.\n",
    "\n",
    "We have the 'else' here because one of our ingredients does not have the token 'of' in it. ('four', 'large', 'eggs) is going to require special handling.\n",
    "\n",
    "The two variables that are definied instead take the last item in the list and second to last item respectively.\n",
    "\n",
    "Finally, we append the new two tuples, composed of our digit_value, food, and measurement to our Brownies_as_data list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tfor t in range(len(x)):\n",
    "\t\tif 'of' in x:\n",
    "\t\t\tif x[t] == 'of':\n",
    "\t\t\t\tfood = \" \".join(x[t+1: ])\n",
    "\t\t\t\tmeasurement = x[t-1]\n",
    "\t\telse:\n",
    "\t\t\tfood = x[-1] \n",
    "\t\t\tmeasurement = x[-2]\t\n",
    "\tBrownies_as_data.append((digit_value, food, measurement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ingredient in Brownies:\n",
    "\tx = tokenizer.findall(ingredient)\n",
    "\tfor i in Word_to_number:\n",
    "\t\tif x[0] == i[0]:\n",
    "\t\t\tdigit_value = i[1]\n",
    "\tfor t in range(len(x)):\n",
    "\t\tif 'of' in x:\n",
    "\t\t\tif x[t] == 'of':\n",
    "\t\t\t\tfood = \" \".join(x[t+1: ])\n",
    "\t\t\t\tmeasurement = x[t-1]\n",
    "\t\telse:\n",
    "\t\t\tfood = x[-1] \n",
    "\t\t\tmeasurement = x[-2]\t\n",
    "\tBrownies_as_data.append((digit_value, food, measurement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'butter', 'sticks'), (2, 'vegetable oil', 'tablespoons'), (1, 'sugar', 'cup'), (1, 'brown sugar', 'cup'), (4, 'eggs', 'large'), (1, 'vanilla extract', 'tablespoon'), (1, 'salt', 'teaspoon'), (1, 'flour', 'cup'), (7, 'chocolate', 'ounces')]\n"
     ]
    }
   ],
   "source": [
    "print(Brownies_as_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
