{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reading at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workshop is focused on turning annotations into usable data for Natural Language Processing applications. It focuses primarily on defining and evaluating a formal feature across texts. We will be producing what is referred to as \"Gold Standard\" Data and then (briefly) seeing what we can do with this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install attachment-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from termcolor import colored, cprint\n",
    "import imaplib\n",
    "import requests\n",
    "import spacy\n",
    "import attachment_downloader\n",
    "from email import encoders\n",
    "from email.mime.base import MIMEBase\n",
    "import os\n",
    "import smtplib\n",
    "import csv\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.message import Message\n",
    "from email.mime.text import MIMEText\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logsitics and Scraping Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding a source of clean, easily parsable text is a cornerstone of most DH work. Clean text is available as a string (one of four data types) rather than a pdf or image. We'll be scraping a website for clean text and applying a few processes to make it usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_results_to_malcolm(annotation_results, filename):\n",
    "\n",
    "    COMMASPACE = ', '\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = 'Annotation Results'\n",
    "    emailfrom = \"lubinworkshop@gmail.com\"\n",
    "    emailto = ['mtb236@cornell.edu', \"lubinworkshop@gmail.com\"]\n",
    "\n",
    "    msg['From'] = emailfrom\n",
    "    msg['To'] = COMMASPACE.join(emailto)\n",
    "    msg.preamble = 'List of  audit records '\n",
    "    csvfiles = [filename]\n",
    "\n",
    "    for csv in csvfiles:\n",
    "            print(csv)\n",
    "            with open(csv) as fp:\n",
    "                record = MIMEBase('application', 'octet-stream')\n",
    "                record.set_payload(fp.read())\n",
    "                encoders.encode_base64(record)\n",
    "                record.add_header('Content-Disposition', 'attachment',\n",
    "                                  filename=os.path.basename(csv))\n",
    "            msg.attach(record)\n",
    "\n",
    "    print (\"INFO: \")\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "    server.login(\"lubinworkshop@gmail.com\", 'raven1119')\n",
    "    server.sendmail(emailfrom, emailto, msg.as_string())\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "result = requests.get(\"http://xroads.virginia.edu/~hyper/POE/masque.html\")\n",
    "poe_masque = [line for line in result.text.splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifies paragraphs in html#\n",
    "def para_helper(data):\n",
    "    para = []\n",
    "    for line in range(len(data)):\n",
    "        if \"<p>\" in data[line]:\n",
    "            para.append(line)\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the start and end of paragraph as a string#\n",
    "def para_extractor(data):\n",
    "    p_list = para_helper(data)\n",
    "    paragraph = []\n",
    "    for item in range(len(p_list)):\n",
    "        if item >= len(p_list) -1:\n",
    "            pass\n",
    "        else:\n",
    "            paragraph.append(data[p_list[item]:p_list[item+1]])\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_clean(data):\n",
    "    p_data = para_extractor(data)\n",
    "    cleaned_story = []\n",
    "    for paragraph in p_data:\n",
    "        cleaned_paragraph = []\n",
    "        for line in paragraph:\n",
    "            cleaned_line = remove_html_tags(line)\n",
    "            if len(cleaned_line) > 3:\n",
    "                cleaned_paragraph.append(cleaned_line)\n",
    "        if len(cleaned_paragraph) > 1:\n",
    "            cleaned_story.append(\" \".join(cleaned_paragraph))\n",
    "    return cleaned_story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidying Text for Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While text in just a string can be more than enough for most applications, adding formatting information will allow us to localize the effects we're noticing; knowing the chapter, sentence, and word position can be invaluable to analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenize_and_tag(data):\n",
    "    story = para_clean(data)\n",
    "    tagged = []\n",
    "    for paragraph_number in range(len(story)):\n",
    "        paragraph = nlp(story[paragraph_number])\n",
    "        sentences = [sent.string.strip() for sent in paragraph.sents]\n",
    "        for sentence_number in range(len(sentences)):\n",
    "            tagged.append((sentences[sentence_number], paragraph_number, sentence_number))\n",
    "    return tagged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = sentence_tokenize_and_tag(poe_masque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation and Annotation Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Crowdsource Annotation Rules Here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_annotator(sentence_tokenized_data):\n",
    "    annotation_results = []\n",
    "    count = 0\n",
    "    while count != len(sentence_tokenized_data):  \n",
    "        print(colored(sentence_tokenized_data[count][0],'blue', attrs=['bold']))\n",
    "        variable = input(\"Feature Present? yes = f or no = j\")\n",
    "        if variable == 'f':\n",
    "            annotation_results.append([sentence_tokenized_data[count][0],sentence_tokenized_data[count][1], sentence_tokenized_data[count][2], 1])\n",
    "            count +=1\n",
    "            clear_output()\n",
    "        elif variable == 'j':\n",
    "            annotation_results.append([sentence_tokenized_data[count][0],sentence_tokenized_data[count][1], sentence_tokenized_data[count][2],0])\n",
    "            count +=1\n",
    "            clear_output()\n",
    "        else:\n",
    "            print(\"Not a valid input. Please stop trying to sabotage my workshop.\")\n",
    "    return(annotation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_results = basic_annotator(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add last name in both the first and last line#\n",
    "with open(\"LASTNAME_masque_annotation_results.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(annotation_results)\n",
    "email_results_to_malcolm(annotation_results, \"LASTNAME_masque_annotation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_annotations(annotation_results):\n",
    "    paragraph = []\n",
    "    for line in range(len(annotation_results)):\n",
    "        element_colors = {'G': 'grey', 'Y': 'yellow'}\n",
    "        if annotation_results[line - 1][1] == annotation_results[line][1]:\n",
    "            line_text = annotation_results[line][0]\n",
    "            if annotation_results[line][3] == 1:\n",
    "                paragraph.append([\"Y\",line_text])\n",
    "            else:\n",
    "                paragraph.append([\"G\",line_text])\n",
    "        else:\n",
    "            print(\" \".join(colored(element[1], element_colors[element[0]]) for element in paragraph))\n",
    "            paragraph =[]\n",
    "            line_text =  \"     \" + annotation_results[line][0]\n",
    "            if annotation_results[line][3] == 1:\n",
    "                paragraph.append([\"Y\",line_text])\n",
    "            else:\n",
    "                paragraph.append([\"G\",line_text])\n",
    "    print(\" \".join(colored(element[1], element_colors[element[0]]) for element in paragraph))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_annotations(annotation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_Mimno = re.compile(\"\\w[\\w\\-\\']*\\w|\\w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_line_graph(annotation_results):\n",
    "    x = range(len(annotation_results))\n",
    "    y = []\n",
    "    for line in annotation_results:\n",
    "        if line[3] == 1:\n",
    "            score = len(wp_Mimno.findall(line[0]))\n",
    "            y.append(score)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('Narrative')\n",
    "    plt.ylabel('# of Tokens')\n",
    "    plt.title('Feature Progression')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_line_graph(annotation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_bar_graph(annotation_results):\n",
    "    x = 1\n",
    "    y = []\n",
    "    count = 0\n",
    "    for line in range(len(annotation_results)):\n",
    "        if annotation_results[line - 1][1] == annotation_results[line][1]:\n",
    "            if annotation_results[line][3] == 1:\n",
    "                count += 1\n",
    "        else:\n",
    "            x += 1\n",
    "            y.append(count)\n",
    "            count = 0\n",
    "    y.append(count)\n",
    "    z = max(y) +2\n",
    "    plt.bar(range(x), y)\n",
    "    plt.xlabel('Paragraph Number')\n",
    "    plt.ylabel('# of Sentences')\n",
    "    plt.title('Feature Progression')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_bar_graph(annotation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bar_graph(annotation_results):\n",
    "    x = 1\n",
    "    y = []\n",
    "    count = 0\n",
    "    word_count =0\n",
    "    for line in range(len(annotation_results)):\n",
    "        if annotation_results[line - 1][1] == annotation_results[line][1]:\n",
    "            if annotation_results[line][3] == 1:\n",
    "                count += 1\n",
    "                word_count += len(wp_Mimno.findall(annotation_results[line][0]))\n",
    "        else:\n",
    "            x += 1\n",
    "            if count > 0:\n",
    "                y.append(word_count/count)\n",
    "            else:\n",
    "                y.append(0)\n",
    "            count = 0\n",
    "            word_count =0\n",
    "    if count > 0:\n",
    "        y.append(count/word_count)\n",
    "    else:\n",
    "        y.append(0)\n",
    "    plt.bar(range(x), y)\n",
    "    plt.xlabel('Paragraph Number')\n",
    "    plt.ylabel('# of tokens/# of sentences')\n",
    "    plt.title('Feature Progression')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_bar_graph(annotation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Annotation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interannotator agreement is important for producing gold standard data; if annotation guidelines allow for too much flexibility or are not clear enough, it is difficult to say with confidence that the feature you think you are observing is being observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get class CSV files#\n",
    "!attachment-downloader --host imap.gmail.com --username lubinworkshop@gmail.com --password raven1119 \\\\\n",
    "    --imap-folder Inbox --output ~/Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "group_masque_results_csvs = glob.glob(\"*_masque_annotation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_masque_results_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_group_results(results):\n",
    "    group_score= []\n",
    "    count = 0\n",
    "    for filename in results:\n",
    "        with open(filename) as f: \n",
    "            file = csv.reader(f, delimiter=',')\n",
    "            if count == 0:\n",
    "                for row in file:\n",
    "                    group_score.append(int(row[3]))\n",
    "                count += 1\n",
    "            else:\n",
    "                lc = 0\n",
    "                for row in file:\n",
    "                    group_score[lc] = group_score[lc] + int(row[3])\n",
    "                    lc += 1\n",
    "    return(group_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_masque_results = calculate_group_results(group_masque_results_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(group_masque_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disagreement(group_results):\n",
    "    complete = 0\n",
    "    majority = 0\n",
    "    comp_line = []\n",
    "    maj_line = []\n",
    "    full = max(group_results)\n",
    "    for line in range(len(group_results)):\n",
    "        if group_results[line] == full or group_results[line] == 0:\n",
    "            complete += 1\n",
    "            comp_line.append(line)\n",
    "        elif line != group_results[line] and line >= group_results[line]/2:\n",
    "            majority += 1\n",
    "            maj_line.append(line)\n",
    "    print(complete)\n",
    "    print(majority)\n",
    "    return ([comp_line, maj_line])\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_majority_lines(annotation_results, group_results):\n",
    "    maj_dis = calculate_disagreement(group_results)[1]\n",
    "    for line in maj_dis:\n",
    "        print(annotation_results[line][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_majority_lines(annotation_results, group_masque_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide on disagreed lines, update accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revise Guidelines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group_One\n",
    "#shorter#\n",
    "telltale = requests.get(\"http://xroads.virginia.edu/~hyper/POE/telltale.html\")\n",
    "poe_telltale = [line for line in telltale.text.splitlines()]\n",
    "telltale_sent = sentence_tokenize_and_tag(poe_telltale)\n",
    "telltale_results = basic_annotator(telltale_sent)\n",
    "\n",
    "#Add last name before running cell#\n",
    "with open(\"LASTNAME_telltale_annotation_results.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(telltale_results)\n",
    "email_results_to_malcolm(annotation_results, \"LASTNAME_telltale_annotation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group_Two\n",
    "#medium#\n",
    "result = requests.get(\"http://xroads.virginia.edu/~hyper/POE/fact.html\")\n",
    "poe_valdemar = [line for line in result.text.splitlines()]\n",
    "valdemar_sent = sentence_tokenize_and_tag(poe_valdemar)\n",
    "valdemar_results = basic_annotator(valdemar_sent)\n",
    "\n",
    "#Add last name before running cell#\n",
    "with open(\"LASTNAME_valdemar_annotation_results.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(valdemar_results)\n",
    "email_results_to_malcolm(annotation_results, \"LASTNAME_valdemar_annotation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group_Three\n",
    "#longer#\n",
    "result = requests.get(\"http://xroads.virginia.edu/~hyper/POE/fall.html\")\n",
    "poe_usher = [line for line in result.text.splitlines()]\n",
    "usher_sent = sentence_tokenize_and_tag(poe_usher)\n",
    "usher_results = basic_annotator(usher_sent)\n",
    "\n",
    "#Add last name before running cell#\n",
    "with open(\"LASTNAME_usher_annotation_results.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(usher_results)\n",
    "email_results_to_malcolm(annotation_results, \"LASTNAME_usher_annotation_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get CSV files#\n",
    "!attachment-downloader --host imap.gmail.com --username lubinworkshop@gmail.com --password raven1119 \\\\\n",
    "    --imap-folder Inbox --output ~/Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_telltale_results_csvs = glob.glob(\"*_telltale_annotation_results.csv\")\n",
    "show_majority_lines(telltale_results, group_telltale_results_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_valdemar_results_csvs = glob.glob(\"*_valdemar_annotation_results.csv\")\n",
    "show_majority_lines(valdemar_results, group_valdemar_results_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_usher_results_csvs = glob.glob(\"*_usher_annotation_results.csv\")\n",
    "show_majority_lines(usher_results, group_usher_results_csvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get CSV files#\n",
    "!attachment-downloader --host imap.gmail.com --username lubinworkshop@gmail.com --password raven1119 \\\\\n",
    "    --imap-folder Inbox --output ~/Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this file by hand#\n",
    "group_annotation_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"compiled_annotation_results.csv\") as f: \n",
    "    file = csv.reader(f, delimiter=',')\n",
    "        for row in file:\n",
    "            group_annotation_results.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pandas.DataFrame()\n",
    "trainDF['text'] = [i[0] for i in group_annotation_results]\n",
    "trainDF['label'] = [i[1] for i in group_annotation_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = train_model(svm.SVC(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"SVM: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
